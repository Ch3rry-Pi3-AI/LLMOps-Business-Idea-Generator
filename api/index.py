# -------------------------------------------------------------------
# üîê LLMOps Business Idea Generator ‚Äì FastAPI Application with Clerk Auth
# -------------------------------------------------------------------
"""
This module defines the authenticated FastAPI backend for the
LLMOps Business Idea Generator. It extends the previous streaming
version by adding **user authentication** via Clerk.

Users must now be authenticated to access the `/api` endpoint.
The Clerk-provided JWT is verified using the JWKS URL configured
in environment variables. This ensures that only signed-in users
can generate new business ideas.

Notes
-----
- Uses `fastapi-clerk-auth` for Clerk token verification.
- Streams model responses in real time (SSE).
- Authenticated user IDs are accessible via `creds.decoded["sub"]`.
- Ready for integration with user-specific databases or analytics.
"""

# -------------------------------------------------------------------
# üì¶ Imports
# -------------------------------------------------------------------
import os
from fastapi import FastAPI, Depends  # type: ignore
from fastapi.responses import StreamingResponse  # type: ignore
from fastapi_clerk_auth import (
    ClerkConfig,
    ClerkHTTPBearer,
    HTTPAuthorizationCredentials
)  # type: ignore
from openai import OpenAI  # type: ignore


# -------------------------------------------------------------------
# ‚öôÔ∏è Application Initialisation
# -------------------------------------------------------------------
app = FastAPI(
    title="LLMOps Business Idea Generator ‚Äì Authenticated Streaming",
    description="FastAPI backend with Clerk authentication and live streaming output.",
    version="0.4.0",
)


# -------------------------------------------------------------------
# üîë Clerk Authentication Configuration
# -------------------------------------------------------------------
# Initialise Clerk authentication guard using JWKS URL from environment variables.
clerk_config = ClerkConfig(jwks_url=os.getenv("CLERK_JWKS_URL"))
clerk_guard = ClerkHTTPBearer(clerk_config)


# -------------------------------------------------------------------
# üí° Authenticated Business Idea Streaming Endpoint
# -------------------------------------------------------------------
@app.get("/api")
def idea(creds: HTTPAuthorizationCredentials = Depends(clerk_guard)):
    """
    Generate and stream a new business idea for authenticated users.

    This endpoint validates the request using Clerk authentication
    before calling the OpenAI API. The response is streamed in real time
    to the frontend as Markdown-formatted text.

    Parameters
    ----------
    creds : HTTPAuthorizationCredentials, optional
        The validated Clerk token credentials automatically injected
        by FastAPI's dependency system.

    Returns
    -------
    StreamingResponse
        A text/event-stream that yields incremental Markdown-formatted
        business idea content generated by the model.
    """
    # Extract user ID from Clerk JWT
    user_id = creds.decoded["sub"]

    # -------------------------------------------------------------------
    # üß≠ Optional: Use user_id for advanced features
    # -------------------------------------------------------------------
    # - Track user-specific usage or quotas
    # - Store generated ideas in a database
    # - Apply personalised model settings
    # - Analyse request metrics per user

    # Instantiate OpenAI client
    client = OpenAI()

    # Define prompt for structured Markdown output
    prompt = [
        {
            "role": "user",
            "content": (
                "Reply with a new business idea for AI Agents, "
                "formatted with headings, sub-headings and bullet points."
            ),
        }
    ]

    # Create a streaming chat completion request
    stream = client.chat.completions.create(
        model="gpt-5-nano",
        messages=prompt,
        stream=True
    )

    # -------------------------------------------------------------------
    # üîÑ Generator Function ‚Äì Stream Response Data
    # -------------------------------------------------------------------
    def event_stream():
        """
        Stream incremental Markdown text as SSE (Server-Sent Events).
        """
        for chunk in stream:
            text = chunk.choices[0].delta.content
            if text:
                # Split the output into cleanly formatted lines
                lines = text.split("\n")

                # Yield each line with double newline to maintain SSE formatting
                for line in lines[:-1]:
                    yield f"data: {line}\n\n"
                    yield "data:  \n"
                yield f"data: {lines[-1]}\n\n"

    # Return the streaming response with event-stream MIME type
    return StreamingResponse(event_stream(), media_type="text/event-stream")
